{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cb20fffa-23df-454a-a88e-3eef3fa9b069",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create dataset from MELD\n",
    "from typing import List, Union, Any\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ea63bffc-7ac0-4309-bcf2-7484e42a23ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = {}\n",
    "conf[\"raw_MELD_path\"] = \"/home/n/nguyenpk/CS6208/GNN_ERC/data/MELD.Raw\"\n",
    "conf[\"raw_Daily_Dailog_path\"] = \"/home/n/nguyenpk/CS6208/GNN_ERC/data/Dialog\" \n",
    "conf[\"raw_IEMOCAP_path\"] = \"/home/n/nguyenpk/IEMOCAP_full_release\"\n",
    "conf[\"pickle_IEMOCAP_path\"] = \"/home/n/nguyenpk/CS6208/GNN_ERC/data/IEMOCAP_features.pkl\"\n",
    "# conf[\"glove_path\"] = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b2532aba-6c19-4e54-8545-fbd0fe972550",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Daily_Dialog_preprocessing:\n",
    "    \"\"\"This class \n",
    "    just use to wrap up\n",
    "    the function\"\"\"\n",
    "    def my_reading_conv(self, dpath: str, \n",
    "                        lsplit: str=\" \", to_int: bool=False) -> List[Any]:\n",
    "        \"\"\" This function reading from dpath and return the output\n",
    "        Input:\n",
    "         - dpath: the path of data\n",
    "         - split: split parameters for every line \n",
    "        Output: list of the input from dpath. \n",
    "        \"\"\"\n",
    "\n",
    "        with open(dpath, \"r\") as f:\n",
    "            if to_int:\n",
    "                lines = [[int(i.strip()) for i in line.rstrip().split(lsplit) if i.strip() != ''] for line in f ]\n",
    "            else:\n",
    "                lines = [[i.strip() for i in line.rstrip().split(lsplit) if i.strip() != ''] for line in f ]\n",
    "        return lines\n",
    "\n",
    "    def reading_DD(self, conv_path: str, \n",
    "                 emo_path: str, \n",
    "                 act_path: Union[str, None]=None, \n",
    "                 topic_path: Union[str, None]=None) -> dict:\n",
    "        \"\"\" This function is create the dataset from multiple path of Daily Dailog\n",
    "        Input:\n",
    "            - conv_path: path of conversation data\n",
    "            - emo_path: path of the emotional data\n",
    "            - act_path: path of action data\n",
    "            - topic_path: path of topic data\n",
    "        Output: The dictionary the have \n",
    "            {\n",
    "            \"conv\": the list of the converstion[each conversation have number of ulterance]\n",
    "            \"speakers\": output the auto generate speaker based on the id of conv\n",
    "            \"emo\" : the list of emotion\n",
    "            \"act\":  the list of act\n",
    "            \"topic\": the list of topic\n",
    "            }\n",
    "        \"\"\"\n",
    "        conversations = self.my_reading_conv(conv_path, \"__eou__\")\n",
    "        emotions = self.my_reading_conv(emo_path, to_int=True)\n",
    "        speakers = [list(map(lambda i: i%2, range(0, len(ic)))) for ic in conversations]\n",
    "        ### This process to check if the length when we create is different ###\n",
    "        len_conv = list(map(lambda x: len(x), conversations))\n",
    "        len_emo = list(map(lambda x: len(x), emotions))\n",
    "        check1 = all(item in len_conv for item in len_emo)\n",
    "        assert check1, \"Mismatch label and data\"\n",
    "        len_speaker = list(map(lambda x: len(x), speakers))\n",
    "        check2= all(item in len_speaker for item in len_emo), \"Mismatch speaker and data\"\n",
    "        acts = []\n",
    "        topics =[]\n",
    "        if act_path:\n",
    "            acts = self.my_reading_conv(act_path, to_int=True)\n",
    "            len_acts = list(map(lambda x: len(x), acts))\n",
    "            check2= all(item in len_acts for item in len_emo)\n",
    "            assert check2, \"Mismatch actions and data\"\n",
    "        if topic_path:\n",
    "            topics =  self.my_reading_conv(topic_path, to_int=True)\n",
    "            topics = list(map(lambda x: x[0], acts))\n",
    "            assert check2, \"Mismatch topic and data\"\n",
    "        out = {'conversation': conversations, 'speakers':speakers,  'emotions': emotions, 'actions':acts, 'topics':topics}\n",
    "        return out\n",
    "\n",
    "    def raw_DD_DS_segment(self, basepath: str)->dict:\n",
    "        \"\"\" This function will recevide the base path and read \n",
    "        for train, test, valid for each data \n",
    "        Input:\n",
    "            - basepath: the path the have subpath 'train', 'valid' and 'test' inside\n",
    "        Output: dictionary of every 'train', 'test' and 'valid'\n",
    "            - rs {\n",
    "            'train': {'conversations', 'speakers', 'emotions', 'actions', 'topics'}\n",
    "            'test': {'conversations', 'speakers', 'emotions', 'actions', 'topics'}\n",
    "            'valid': {'conversations', 'speakers', 'emotions', 'actions', 'topics'}\n",
    "            }\n",
    "        \"\"\"\n",
    "        def create_subpath(substr: str) -> List[str]: \n",
    "            \"\"\" return the sub path base on substr \"\"\"\n",
    "            conv_path = os.path.join(basepath, substr, 'dialogues_{}.txt'.format(substr))\n",
    "            emo_path  = os.path.join(basepath, substr, 'dialogues_emotion_{}.txt'.format(substr))\n",
    "            act_path  = os.path.join(basepath, substr, 'dialogues_act_{}.txt'.format(substr))\n",
    "            return conv_path, emo_path, act_path\n",
    "        train_conv, train_emo, train_act = create_subpath('train')\n",
    "        test_conv, test_emo, test_act = create_subpath('test')\n",
    "        valid_conv, valid_emo, valid_act = create_subpath('validation')\n",
    "        out_rs = {'train': self.reading_DD(train_conv, train_emo, train_act),\n",
    "                  'test': self.reading_DD(test_conv, test_emo, test_act),\n",
    "                  'dev': self.reading_DD(valid_conv, valid_emo, valid_act),\n",
    "                 }\n",
    "        return out_rs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "66440099-d11a-47f7-9cd6-a023851c76a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dd_tool = Daily_Dialog_preprocessing()\n",
    "Diaglog_data = dd_tool.raw_DD_DS_segment(\"/home/n/nguyenpk/CS6208/GNN_ERC/data/Dialog\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f5c218cc-ad0d-40cc-b61c-5089ea1b8037",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = raw_DD_DS_segment(\"/home/n/nguyenpk/CS6208/GNN_ERC/data/Dialog\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9223c88e-77d2-4cd6-9f4e-5dbf0dda6750",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dialogues_act.txt      dialogues_topic.txt  test.zip   validation\n",
      "dialogues_emotion.txt  readme.txt\t    train      validation.zip\n",
      "dialogues_text.txt     test\t\t    train.zip\n"
     ]
    }
   ],
   "source": [
    "# !ls /home/n/nguyenpk/CS6208/GNN_ERC/data/Dialog/\n",
    "# #-\n",
    "# conv_path = \"/home/n/nguyenpk/CS6208/GNN_ERC/data/Dialog/dialogues_text.txt\"\n",
    "# emo_path  = \"/home/n/nguyenpk/CS6208/GNN_ERC/data/Dialog/dialogues_emotion.txt\"\n",
    "# act_path  = \"/home/n/nguyenpk/CS6208/GNN_ERC/data/Dialog/dialogues_act.txt\"\n",
    "# topic_path = \"/home/n/nguyenpk/CS6208/GNN_ERC/data/Dialog/dialogues_topic.txt\"\n",
    "# out1 = reading_DD(conv_path, emo_path, act_path, topic_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d8967632-6f6b-4523-8bbc-f1603d9f8016",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ### 1st version using pytorch \n",
    "# import torch\n",
    "# from torchtext.data import get_tokenizer # can use from spacy \n",
    "# tokenizer = get_tokenizer(\"basic_english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0572f4f9-7ce2-4960-bcbe-42db97e44adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "## -- checking the tf version!!! --\n",
    "# TENSORFLOW\n",
    "# from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "# from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# import numpy as np\n",
    "\n",
    "# def preprocess_text(x):\n",
    "#     for punct in '\"!&?.,}-/<>#$%\\()*+:;=?@[\\\\]^_`|\\~':\n",
    "#         x = x.replace(punct, '')\n",
    "#     # x = ' '.join(x.split())\n",
    "#     split = x.split()\n",
    "#     for i in \n",
    "#     x = x.lower()\n",
    "#     return x\n",
    "\n",
    "# def load_pretrained_glove(glove_path):\n",
    "#     print(\"Loading GloVe model, this can take some time...\")\n",
    "#     glv_vector = {}\n",
    "#     # Put your glove embedding path here\n",
    "#     f = open(glove_path, encoding='utf-8')\n",
    "\n",
    "#     for line in f:\n",
    "#         values = line.split()\n",
    "#         word = values[0]\n",
    "#         try:\n",
    "#             coefs = np.asarray(values[1:], dtype='float')\n",
    "#             glv_vector[word] = coefs\n",
    "#         except ValueError:\n",
    "#             continue\n",
    "#     f.close()\n",
    "#     print(\"Completed loading pretrained GloVe model.\")\n",
    "#     return glv_vector\n",
    "# u_train = [ list(map(lambda x: preprocess_text(x), i)) for i in out['conversation']] \n",
    "# tokenizer = Tokenizer()\n",
    "# tokenizer.fit_on_texts(u_train)\n",
    "# glv_vector = load_pretrained_glove(\"/home/n/nguyenpk/CS6220/data/glove.840B.300d.txt\")\n",
    "# word_vector_length = len(glv_vector['the'])\n",
    "# word_index = tokenizer.word_index\n",
    "# inv_word_index = {v: k for k, v in word_index.items()}\n",
    "# num_unique_words = len(word_index)\n",
    "# glv_embedding_matrix = np.zeros((num_unique_words + 1, word_vector_length))\n",
    "# #---\n",
    "\n",
    "# for j in range(1, num_unique_words + 1):\n",
    "#     try:\n",
    "#         glv_embedding_matrix[j] = glv_vector[inv_word_index[j]]\n",
    "#     except KeyError:\n",
    "#         glv_embedding_matrix[j] = np.random.randn(word_vector_length) / 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3d311259-4101-4bf7-a3e7-754517d8ff10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torchtext\n",
    "# from torchtext.data import get_tokenizer\n",
    "\n",
    "# train_DD, test_DD, valid_DD = out['train'], out['test'], out['valid']\n",
    "# #\n",
    "# conv_train = train_DD['conversation']\n",
    "# tokenizer = get_tokenizer(\"basic_english\")\n",
    "# tokens = tokenizer()\n",
    "# def preprocess_text(x):\n",
    "#     for punct in '\"!&?.,}-/<>#$%\\()*+:;=?@[\\\\]^_`|\\~':\n",
    "#         x = x.replace(punct, '')\n",
    "#     # x = ' '.join(x.split())\n",
    "#     split = x.split()\n",
    "#     x = x.lower()\n",
    "#     return x\n",
    "# u_train =  [ list(map(lambda x: preprocess_text(x), i)) for i in conv_train] \n",
    "# token = tokenizer(u_train) \n",
    "# import torchtext"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96eb2d0f-a4f5-49c8-96c1-622aad5ac9a0",
   "metadata": {},
   "source": [
    "### Preprocessing for MELD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6a831623-0e4d-4d3e-a844-0e6f9e965625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev_sent_emo.csv\t     README.txt\t\ttrain_sent_emo.csv\n",
      "dev.tar.gz\t\t     test_sent_emo.csv\ttrain_splits\n",
      "output_repeated_splits_test  test.tar.gz\ttrain.tar.gz\n"
     ]
    }
   ],
   "source": [
    "0: no emotion, 1: anger, 2: disgust, 3: fear, 4: happiness, 5: sadness, 6: surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "761b1657-5d46-41a8-af8b-70c6638cc971",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "path_link = \"/home/n/nguyenpk/CS6208/GNN_ERC/data/MELD.Raw/train_sent_emo.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b76bdec0-ecb4-40d2-a6ec-c5b72183d9b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['neutral', 'surprise', 'fear', 'sadness', 'joy', 'disgust',\n",
       "       'anger'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Emotion'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f1de46f1-1cb8-424f-960a-51f17fe451a3",
   "metadata": {},
   "outputs": [],
   "source": [
    " # 0: no emotion, 1: anger, 2: disgust, 3: fear, 4: happiness, 5: sadness, 6: surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "334e8b96-f046-4567-8080-3a509e1b8a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MELD_preprocessing:\n",
    "    \"\"\" \n",
    "    This class just keep all of the pre processing MELD script in one sample\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.mapping_emo_label_MELD = {\n",
    "                'neutral': 0, \n",
    "                'anger':1, \n",
    "                'disgust':2, \n",
    "                'fear': 3,\n",
    "                'joy': 4, \n",
    "                'sadness':5, \n",
    "                'surprise':6,\n",
    "            }\n",
    "    def read_from_MELD(self, path_link: str)->dict:\n",
    "        \"\"\"\n",
    "        Input: the link to csv MELD dataset \n",
    "        Output: the preprocessing MELD\n",
    "        \"\"\"\n",
    "        data = pd.read_csv(path_link)\n",
    "        def preprocessingMELD_col(cols: str):\n",
    "            \"\"\" \n",
    "            \"\"\"\n",
    "            uid = list(cols.Utterance_ID)\n",
    "            ultereance = list(cols.Utterance)\n",
    "            speaker = list(cols.Speaker)\n",
    "            emotion = list(cols.Emotion)\n",
    "            sr_out = {}\n",
    "            sr_out['Utterance_ID'] = uid\n",
    "            sr_out['conversation'] = ultereance\n",
    "            sr_out['emotions_raw'] = emotion\n",
    "            sr_out[\"emotions\"] = [self.mapping_emo_label_MELD.get(i) for i in emotion]\n",
    "            sr_out[\"Speaker_raw\"] = speaker\n",
    "            map_sp = {}\n",
    "            isp = 0\n",
    "            for ii in speaker:\n",
    "                if ii not in map_sp.keys():\n",
    "                    map_sp[ii] = isp\n",
    "                    isp = isp + 1\n",
    "            sr_out[\"speakers\"] = [map_sp.get(i) for i in speaker]\n",
    "            sr_out[\"num_speakers\"] = max(map_sp.values()) + 1\n",
    "            return pd.Series(sr_out)\n",
    "\n",
    "\n",
    "        icols = [ 'Utterance_ID', 'Utterance', 'Speaker', 'Emotion']\n",
    "        data_process = data.groupby('Dialogue_ID')[icols].apply(lambda x: preprocessingMELD_col(x)).reset_index()\n",
    "\n",
    "        rs = {}\n",
    "        for i in data_process.columns:\n",
    "            rs[i] = data_process[i].to_list()\n",
    "        return rs\n",
    "\n",
    "    def raw_MELD_DS_segment(self, basepath: str)->dict:\n",
    "        \"\"\" \n",
    "        This function output the train, test, valid of the MELD DATA set \n",
    "        Input: \n",
    "        - basepath: the string path, in this path will have these file \n",
    "            + dev_sent_emo.csv\n",
    "            + train_sent_emo.csv\n",
    "            + test_sent_emo.csv\n",
    "        Output:\n",
    "        - dictionary of 'train', 'test' and 'dev' test\n",
    "        \"\"\"\n",
    "        train_path = os.path.join(basepath, \"train_sent_emo.csv\")\n",
    "        test_path = os.path.join(basepath, \"test_sent_emo.csv\")\n",
    "        valid_path = os.path.join(basepath, \"dev_sent_emo.csv\")\n",
    "        rs = {}\n",
    "        rs['train'] = self.read_from_MELD(train_path)\n",
    "        rs['test']  = self.read_from_MELD(test_path)\n",
    "        rs['dev'] = self.read_from_MELD(valid_path)\n",
    "        rs['mapping_emo'] = self.mapping_emo_label_MELD\n",
    "        return rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9a79b50f-28a0-4347-a217-2a3b78cda0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "meld_tool = MELD_preprocessing()\n",
    "meld_raw = meld_tool.raw_MELD_DS_segment(\"/home/n/nguyenpk/CS6208/GNN_ERC/data/MELD.Raw/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45b058f8-666d-4823-ad88-5eec3553a6fa",
   "metadata": {},
   "source": [
    "## PREPROCESSING IEMOCAP DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8182e49e-7b88-42ec-b1e7-c1d6b118ed7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_file = conf[\"pickle_IEMOCAP_path\"]\n",
    "videoIDs, videoSpeakers, videoLabels, \\\n",
    "_, _, _, videoSentence, trainVid, testVid  = pd.read_pickle(path_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "id": "fd492bf9-a362-465a-b24b-2a32f8443c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class IEMOCAP_preprocessing: \n",
    "    \"\"\" \n",
    "    This class just keep all of the pre processing IEMOCAP  script in one \n",
    "    \"\"\"\n",
    "    def __init__(self, map_label={}):\n",
    "        self.map_emo_label = {\n",
    "            'hap':0, \n",
    "            'sad':1, \n",
    "            'neu':2, \n",
    "            'ang':3, \n",
    "            'exc':4, \n",
    "            'fru':5}\n",
    "        self.map_speaker = {\n",
    "            'M': 0, \n",
    "            'F': 1\n",
    "        }\n",
    "        self.map_emo_label.update(map_label)\n",
    "        \n",
    "    def create_IEMOCAP_from_pkl(self, pkl_file: str) ->dict:\n",
    "        \"\"\"\n",
    "        This function output the train, test, valid of the IEMOCAP DATA set \n",
    "            Input: \n",
    "            - pkl_file: IEMOCAP_feature.pickle file the author used\n",
    "            Output:\n",
    "            - dictionary of 'train', 'test' and 'valid' test\n",
    "        \"\"\"\n",
    "        videoIDs, videoSpeakers, videoLabels, \\\n",
    "        _, _, _, videoSentence, trainVid, testVid  = pd.read_pickle(pkl_file)\n",
    "        dev_size = int(len(trainVid)*0.1) ### as their method\n",
    "        train_video, valid_video = trainVid[dev_size:], trainVid[:dev_size]\n",
    "        def get_data(list_idx: List[str])->dict:\n",
    "            conv = []\n",
    "            speaks = []\n",
    "            emos = []\n",
    "            #----\n",
    "            for idx in list_idx:\n",
    "                conv.append(videoSentence[idx])\n",
    "                speaks.append([self.map_speaker.get(i) for i in videoSpeakers[idx]])\n",
    "                emos.append([self.map_emo_label.get(i, i) for i in videoLabels[idx]]) #in case it already transform use itself\n",
    "            rs = {'conversation': conv, 'speakers': speaks, 'emotions':emos}\n",
    "            return rs\n",
    "        train = get_data(train_video)\n",
    "        test = get_data(testVid)\n",
    "        valid = get_data(valid_video)\n",
    "        out_rs = {'train': train, 'dev': valid, 'test': test, 'train_idx': train_video, 'dev_idx':valid_video, 'test_idx':test, 'mapping_emo': self.map_emo_label}\n",
    "        \n",
    "        return out_rs\n",
    "    \n",
    "    def create_dataset_from_IEMOCAP_base(self, base_path:str)->dict:\n",
    "        \"\"\"\n",
    "        In the original dataset, there is some 10 type of emotions, \n",
    "        including: \n",
    "        Neu = neutral state, Hap = happiness, Sad = sadness, Ang = anger,\n",
    "        Sur = surprise, Fea = fear, Dis = disgust, Fru = frustation, Exc = excited and\n",
    "        Oth = other\n",
    "        {'ang', 'dis', 'exc', 'fea', 'fru', 'hap', 'neu', 'oth', 'sad', 'sur', 'xxx'}\n",
    "        I found that 'xxx' mean 'neu' (coz there is several sentense in this case, \n",
    "        and its sensentce having it own emotions)\n",
    "        base_path of the IEMOCAP\n",
    "        \"\"\"\n",
    "        emo_path = os.path.join(base_path, '{}', 'dialog/EmoEvaluation')\n",
    "        trans_path = os.path.join(base_path, '{}', 'dialog/transcriptions')\n",
    "        sess = [f for f in os.listdir(base_path) if re.match(r'Ses', f)]\n",
    "        dailog_id = []\n",
    "        conversation = []\n",
    "        speakers = []\n",
    "        emotions = []\n",
    "        def find(x, lines):\n",
    "            \"\"\"Find the line have content x\"\"\"\n",
    "            for ii in lines:\n",
    "                if x in ii:\n",
    "                    return ii\n",
    "            return False\n",
    "\n",
    "        def finding_sub_pattern(ifile_trans:str, ifile_emo:str)->List[Any]:\n",
    "            \"\"\"\n",
    "            This return the one conversation information \n",
    "            \"\"\"\n",
    "\n",
    "            uid = []\n",
    "            speaker =  []\n",
    "            conv = []\n",
    "            emo = []\n",
    "            count = 0\n",
    "            with open(ifile_emo, \"r\") as f:\n",
    "                emo_lines = f.readlines()\n",
    "\n",
    "            with open(ifile_trans, \"r\") as f:\n",
    "                lines = f.readlines()\n",
    "            for line in lines:\n",
    "                iuid, iuterance = line.split(\":\")\n",
    "                if \"Ses\" not in iuid: #remvoe some action and unidentify sensentce label\n",
    "                    continue\n",
    "                iuid = iuid.split(\" \")[0]\n",
    "                eline = find(iuid, emo_lines)\n",
    "                if not eline:\n",
    "                    continue \n",
    "                temp = iuid.split('_')\n",
    "                uid.append(iuid)\n",
    "                speaker.append(self.map_speaker.get(temp[-1][0]))\n",
    "                conv.append(iuterance.strip())\n",
    "                emo.append(eline.split('\\t')[2])\n",
    "            return uid, conv, speaker, emo\n",
    "\n",
    "        #\n",
    "        for isess in sess:\n",
    "            link_Emo = emo_path.format(isess)\n",
    "            link_transcript = trans_path.format(isess)\n",
    "            files = [f for f in os.listdir(link_transcript) if re.match(r'Ses+.*\\.txt', f)]\n",
    "            for ifile in files:\n",
    "                ifile_trans = os.path.join(link_transcript, ifile)\n",
    "                ifile_emo = os.path.join(link_Emo, ifile)\n",
    "                uid, conv, speak, emo = finding_sub_pattern(ifile_trans, ifile_emo)\n",
    "                dailog_id.append(uid)\n",
    "                conversation.append(conv)\n",
    "                speakers.append(speak)\n",
    "                emotions.append(emo)\n",
    "                assert len(uid) == len(conv), \"Check the input\"\n",
    "                assert len(uid) == len(speak) , \"Check the input\"\n",
    "                assert len(uid) == len(emo), \"Check the input {} {}\".format(len(uid), len(emo))\n",
    "\n",
    "        out = {'dailog_id': dailog_id, 'conversation': conversation, 'speakers':speakers, 'emotions':emotions}\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "2e5c2258-da05-42e2-bb55-d85677648278",
   "metadata": {},
   "outputs": [],
   "source": [
    "itool = IEMOCAP_preprocessing()\n",
    "rs = itool.create_IEMOCAP_from_pkl(conf[\"pickle_IEMOCAP_path\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "146ecb2b-0939-4732-b621-d31ef5c4f0f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "checking = itool.create_dataset_from_IEMOCAP_base('/home/n/nguyenpk/IEMOCAP_full_release')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054a1d0a-29a3-4673-b566-5621a0f212f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "424c02b2-23d5-43c9-b648-347e3a6f303c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OTDD",
   "language": "python",
   "name": "otdd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
